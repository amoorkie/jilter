#!/usr/bin/env python3
"""
–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –∏ –Ω–∞–¥—ë–∂–Ω—ã–π Python –ø–∞—Ä—Å–µ—Ä –¥–ª—è Geekjob.ru

–≠—Ç–æ—Ç –ø–∞—Ä—Å–µ—Ä —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ —Å–æ–∑–¥–∞–Ω –¥–ª—è –∑–∞–º–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ Node.js –ø–∞—Ä—Å–µ—Ä–∞
–∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Å–±–æ—Ä –¥–∏–∑–∞–π–Ω–µ—Ä—Å–∫–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π —Å –ø–æ–ª–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö.

–ê–≤—Ç–æ—Ä: AI Assistant
–í–µ—Ä—Å–∏—è: 1.0.0
–î–∞—Ç–∞: 2025-01-02
"""

import os
import sys
import time
import json
import sqlite3
import logging
import argparse
import requests
from datetime import datetime, timedelta
from urllib.parse import urljoin, quote
from bs4 import BeautifulSoup
from typing import List, Dict, Optional, Any
try:
    from simple_text_formatter import extract_formatted_text, clean_text
    from text_cleaner import clean_vacancy_data
except ImportError:
    # Fallback –¥–ª—è —Å–ª—É—á–∞—è, –∫–æ–≥–¥–∞ –º–æ–¥—É–ª—å –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é
    import sys
    import os
    sys.path.append(os.path.dirname(__file__))
    from simple_text_formatter import extract_formatted_text, clean_text
    from text_cleaner import clean_vacancy_data


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
def setup_logging(verbose: bool = False, log_file: str = "geekjob_parser.log"):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    level = logging.DEBUG if verbose else logging.INFO
    
    # –§–æ—Ä–º–∞—Ç—Ç–µ—Ä –¥–ª—è –ª–æ–≥–æ–≤
    formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ—Ä–Ω–µ–≤–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞
    logger = logging.getLogger()
    logger.setLevel(level)
    
    # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    logger.handlers.clear()
    
    # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # –§–∞–π–ª–æ–≤—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
    try:
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ª–æ–≥-—Ñ–∞–π–ª {log_file}: {e}")
    
    return logger


# –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
class VacancyDatabase:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å SQLite –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π"""
    
    def __init__(self, db_path: str = "geekjob_vacancies.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—É –≤–∞–∫–∞–Ω—Å–∏–π
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS vacancies (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        external_id TEXT UNIQUE NOT NULL,
                        source TEXT NOT NULL DEFAULT 'geekjob',
                        url TEXT NOT NULL,
                        title TEXT NOT NULL,
                        company TEXT,
                        salary TEXT,
                        location TEXT,
                        description TEXT,
                        full_description TEXT,
                        requirements TEXT,
                        tasks TEXT,
                        benefits TEXT,
                        conditions TEXT,
                        employment_type TEXT,
                        experience_level TEXT,
                        remote_type TEXT,
                        company_logo TEXT,
                        company_url TEXT,
                        published_at DATETIME,
                        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                        updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                        status TEXT DEFAULT 'pending'
                    )
                """)
                
                # –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_external_id ON vacancies(external_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_source ON vacancies(source)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_created_at ON vacancies(created_at)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_status ON vacancies(status)")
                
                conn.commit()
                logging.info(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {self.db_path}")
                
        except sqlite3.Error as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise
    
    def save_vacancy(self, vacancy_data: Dict[str, Any]) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –≤–∞–∫–∞–Ω—Å–∏—è
                cursor.execute(
                    "SELECT id FROM vacancies WHERE external_id = ? AND source = ?",
                    (vacancy_data['external_id'], vacancy_data.get('source', 'geekjob'))
                )
                
                if cursor.fetchone():
                    logging.debug(f"‚ö†Ô∏è –í–∞–∫–∞–Ω—Å–∏—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {vacancy_data['external_id']}")
                    return False
                
                # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –≤–∞–∫–∞–Ω—Å–∏—é
                cursor.execute("""
                    INSERT INTO vacancies (
                        external_id, source, url, title, company, salary, location,
                        description, full_description, requirements, tasks, benefits, conditions,
                        employment_type, experience_level, remote_type, company_logo, company_url,
                        published_at, status
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    vacancy_data['external_id'],
                    vacancy_data.get('source', 'geekjob'),
                    vacancy_data['url'],
                    vacancy_data['title'],
                    vacancy_data.get('company', ''),
                    vacancy_data.get('salary', ''),
                    vacancy_data.get('location', ''),
                    vacancy_data.get('description', ''),
                    vacancy_data.get('full_description', ''),
                    vacancy_data.get('requirements', ''),
                    vacancy_data.get('tasks', ''),
                    vacancy_data.get('benefits', ''),
                    vacancy_data.get('conditions', ''),
                    vacancy_data.get('employment_type', ''),
                    vacancy_data.get('experience_level', ''),
                    vacancy_data.get('remote_type', ''),
                    vacancy_data.get('company_logo', ''),
                    vacancy_data.get('company_url', ''),
                    vacancy_data.get('published_at'),
                    vacancy_data.get('status', 'pending')
                ))
                
                conn.commit()
                logging.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—è: {vacancy_data['title']} - {vacancy_data.get('company', 'N/A')}")
                return True
                
        except sqlite3.Error as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
            return False
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                cursor.execute("SELECT COUNT(*) FROM vacancies WHERE source = 'geekjob'")
                total = cursor.fetchone()[0]
                
                # –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
                cursor.execute("""
                    SELECT COUNT(*) FROM vacancies 
                    WHERE source = 'geekjob' AND created_at > datetime('now', '-1 day')
                """)
                last_24h = cursor.fetchone()[0]
                
                # –ü–æ —Å—Ç–∞—Ç—É—Å–∞–º
                cursor.execute("""
                    SELECT status, COUNT(*) FROM vacancies 
                    WHERE source = 'geekjob' 
                    GROUP BY status
                """)
                by_status = dict(cursor.fetchall())
                
                # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏
                cursor.execute("""
                    SELECT COUNT(DISTINCT company) FROM vacancies 
                    WHERE source = 'geekjob' AND company != ''
                """)
                unique_companies = cursor.fetchone()[0]
                
                return {
                    'total': total,
                    'last_24h': last_24h,
                    'by_status': by_status,
                    'unique_companies': unique_companies
                }
                
        except sqlite3.Error as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}


# –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –ø–∞—Ä—Å–µ—Ä–∞
class GeekjobParser:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –ø–∞—Ä—Å–µ—Ä–∞ Geekjob.ru"""
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–∏–∑–∞–π–Ω–µ—Ä—Å–∫–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π
    DESIGN_KEYWORDS = [
        '–¥–∏–∑–∞–π–Ω', '–¥–∏–∑–∞–π–Ω–µ—Ä', '–¥–∏–∑–∞–π–Ω–µ—Ä –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤', 'ui/ux', 'ux/ui', '–ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –¥–∏–∑–∞–π–Ω',
        '—Ü–∏—Ñ—Ä–æ–≤–æ–π –¥–∏–∑–∞–π–Ω', '–≤–µ–±-–¥–∏–∑–∞–π–Ω', '–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–Ω—ã–π –¥–∏–∑–∞–π–Ω', '–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –¥–∏–∑–∞–π–Ω',
        '–≤–∏–∑—É–∞–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω', '–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∏–∑–∞–π–Ω', '–¥–∏–∑–∞–π–Ω-–º—ã—à–ª–µ–Ω–∏–µ', 'user experience',
        'user interface', 'ux-–¥–∏–∑–∞–π–Ω–µ—Ä', 'ui-–¥–∏–∑–∞–π–Ω–µ—Ä', '–ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –¥–∏–∑–∞–π–Ω–µ—Ä', '–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –¥–∏–∑–∞–π–Ω–µ—Ä',
        '–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–Ω—ã–π –¥–∏–∑–∞–π–Ω–µ—Ä', '–≤–µ–±-–¥–∏–∑–∞–π–Ω–µ—Ä', '–≤–∏–∑—É–∞–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω–µ—Ä', 'motion-–¥–∏–∑–∞–π–Ω–µ—Ä',
        'ux-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å', '–∞—Ä—Ç-–¥–∏—Ä–µ–∫—Ç–æ—Ä', 'creative director', '–¥–∏–∑–∞–π–Ω–µ—Ä –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–π',
        '–¥–∏–∑–∞–π–Ω–µ—Ä –±—Ä–µ–Ω–¥-–∏–¥–µ–Ω—Ç–∏–∫–∏', '–∏–ª–ª—é—Å—Ç—Ä–∞—Ç–æ—Ä', '3d-–¥–∏–∑–∞–π–Ω–µ—Ä', 'designer', 'ui designer',
        'ux designer', 'product designer', 'visual designer', 'graphic designer', 'web designer',
        'interaction designer', 'motion designer', 'ux researcher', 'art director', 'creative director'
    ]
    
    # –ò—Å–∫–ª—é—á–µ–Ω–∏—è - –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ç–∏–ø—ã –¥–∏–∑–∞–π–Ω–∞
    EXCLUDED_KEYWORDS = [
        '—Ç–µ–∫—Å—Ç–∏–ª—å', '—Ç–µ–∫—Å—Ç–∏–ª—å–Ω—ã–π', '—Ç–∫–∞–Ω—å', '–æ–¥–µ–∂–¥–∞', '–º–æ–¥–∞', 'fashion',
        '—é–≤–µ–ª–∏—Ä–Ω—ã–π', '—é–≤–µ–ª–∏—Ä', '—É–∫—Ä–∞—à–µ–Ω–∏—è', '–±–∏–∂—É—Ç–µ—Ä–∏—è',
        '–º–µ–±–µ–ª—å', '–∏–Ω—Ç–µ—Ä—å–µ—Ä', '–¥–µ–∫–æ—Ä', '–ª–∞–Ω–¥—à–∞—Ñ—Ç', '—Å–∞–¥–æ–≤—ã–π',
        '–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π', '–º–∞—à–∏–Ω–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ', '–∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π',
        '—É–ø–∞–∫–æ–≤–∫–∞', '–ø–æ–ª–∏–≥—Ä–∞—Ñ–∏—è', '–ø–µ—á–∞—Ç—å', '—Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏—è',
        '–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π', '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π', '—Ä–µ—Å—Ç–∞–≤—Ä–∞—Ü–∏—è',
        '–∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–π', '–ø–∞—Ä–∏–∫–º–∞—Ö–µ—Ä', '–º–∞–Ω–∏–∫—é—Ä', '–ø–µ–¥–∏–∫—é—Ä',
        '–∫—É–ª–∏–Ω–∞—Ä–Ω—ã–π', '–∫–æ–Ω–¥–∏—Ç–µ—Ä', '–ø–æ–≤–∞—Ä', '—à–µ—Ñ-–ø–æ–≤–∞—Ä',
        '—Ñ–ª–æ—Ä–∏—Å—Ç–∏–∫–∞', '—Ü–≤–µ—Ç—ã', '–±—É–∫–µ—Ç', '—Å–≤–∞–¥–µ–±–Ω—ã–π',
        '—Ç–∞—Ç—É', '—Ç–∞—Ç—É–∏—Ä–æ–≤–∫–∞', '–ø–∏—Ä—Å–∏–Ω–≥', '–±–æ–¥–∏-–∞—Ä—Ç',
        '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ', '—Ñ–æ—Ç–æ', '–≤–∏–¥–µ–æ', '–º–æ–Ω—Ç–∞–∂',
        '–∑–≤—É–∫', '–∞—É–¥–∏–æ', '–º—É–∑—ã–∫–∞', '–∫–æ–º–ø–æ–∑–∏—Ç–æ—Ä',
        '—Ç–∞–Ω—Ü—ã', '—Ö–æ—Ä–µ–æ–≥—Ä–∞—Ñ', '–±–∞–ª–µ—Ç', '—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ç–∞–Ω–µ—Ü',
        '–∞–∫—Ç–µ—Ä', '–∞–∫—Ç—Ä–∏—Å–∞', '—Ç–µ–∞—Ç—Ä', '–∫–∏–Ω–æ',
        '–ø–∏—Å–∞—Ç–µ–ª—å', '–∂—É—Ä–Ω–∞–ª–∏—Å—Ç', '–∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä', '—Ä–µ–¥–∞–∫—Ç–æ—Ä',
        '–ø–µ—Ä–µ–≤–æ–¥—á–∏–∫', '–ª–∏–Ω–≥–≤–∏—Å—Ç', '—Ñ–∏–ª–æ–ª–æ–≥',
        '–ø—Å–∏—Ö–æ–ª–æ–≥', '–ø—Å–∏—Ö–æ—Ç–µ—Ä–∞–ø–µ–≤—Ç', '–∫–æ—É—á',
        '—Ç—Ä–µ–Ω–µ—Ä', '—Ñ–∏—Ç–Ω–µ—Å', '–π–æ–≥–∞', '–ø–∏–ª–∞—Ç–µ—Å',
        '–º–∞—Å—Å–∞–∂', '–º–∞—Å—Å–∞–∂–∏—Å—Ç', '—Å–ø–∞', '—Å–∞–ª–æ–Ω',
        '–ø—Ä–æ–¥–∞–≤–µ—Ü', '–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç', '–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º',
        '–≤–æ–¥–∏—Ç–µ–ª—å', '–∫—É—Ä—å–µ—Ä', '–ª–æ–≥–∏—Å—Ç', '—Å–∫–ª–∞–¥',
        '–æ—Ö—Ä–∞–Ω–∞', '–æ—Ö—Ä–∞–Ω–Ω–∏–∫', '—Å–µ–∫—Ä–µ—Ç–∞—Ä—å', '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä',
        '—É–±–æ—Ä—â–∏–∫', '—É–±–æ—Ä—â–∏—Ü–∞', '–¥–≤–æ—Ä–Ω–∏–∫', '—Å–∞–¥–æ–≤–Ω–∏–∫',
        '—ç–ª–µ–∫—Ç—Ä–∏–∫', '—Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫', '—Å–ª–µ—Å–∞—Ä—å', '–º–µ—Ö–∞–Ω–∏–∫',
        '—Å–≤–∞—Ä—â–∏–∫', '—Ç–æ–∫–∞—Ä—å', '—Ñ—Ä–µ–∑–µ—Ä–æ–≤—â–∏–∫', '—Å–ª–µ—Å–∞—Ä—å-—Å–±–æ—Ä—â–∏–∫',
        '–º–∞–ª—è—Ä', '—à—Ç—É–∫–∞—Ç—É—Ä', '–ø–ª–∏—Ç–æ—á–Ω–∏–∫', '–∫–∞–º–µ–Ω—â–∏–∫',
        '—Å—Ç–æ–ª—è—Ä', '–ø–ª–æ—Ç–Ω–∏–∫', '–∫—Ä–∞—Å–Ω–æ–¥–µ—Ä–µ–≤—â–∏–∫', '–º–µ–±–µ–ª—å—â–∏–∫',
        '—à–≤–µ—è', '–ø–æ—Ä—Ç–Ω–æ–π', '–∑–∞–∫—Ä–æ–π—â–∏–∫', '–º–æ–¥–µ–ª—å–µ—Ä',
        '–æ–±—É–≤—â–∏–∫', '—Å–∞–ø–æ–∂–Ω–∏–∫', '–∫–æ–∂–µ–≤–Ω–∏–∫', '—Å–∫–æ—Ä–Ω—è–∫',
        '—é–≤–µ–ª–∏—Ä', '–≥—Ä–∞–≤–µ—Ä', '—á–µ–∫–∞–Ω—â–∏–∫', '–ª–∏—Ç–µ–π—â–∏–∫',
        '—Å—Ç–µ–∫–ª–æ–¥—É–≤', '–∫–µ—Ä–∞–º–∏—Å—Ç', '–≥–æ–Ω—á–∞—Ä', '—Å–∫—É–ª—å–ø—Ç–æ—Ä',
        '—Ö—É–¥–æ–∂–Ω–∏–∫', '–∂–∏–≤–æ–ø–∏—Å–µ—Ü', '–≥—Ä–∞—Ñ–∏–∫', '–∏–ª–ª—é—Å—Ç—Ä–∞—Ç–æ—Ä',
        '–∫–∞–ª–ª–∏–≥—Ä–∞—Ñ', '—à—Ä–∏—Ñ—Ç–æ–≤–∏–∫', '—Ç–∏–ø–æ–≥—Ä–∞—Ñ', '–ø–µ—á–∞—Ç–Ω–∏–∫',
        '–ø–µ—Ä–µ–ø–ª–µ—Ç—á–∏–∫', '—Ä–µ—Å—Ç–∞–≤—Ä–∞—Ç–æ—Ä –∫–Ω–∏–≥', '–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å',
        '–∞—Ä—Ö–∏–≤–∞—Ä–∏—É—Å', '–º—É–∑–µ–π–Ω—ã–π —Ä–∞–±–æ—Ç–Ω–∏–∫', '—ç–∫—Å–∫—É—Ä—Å–æ–≤–æ–¥',
        '–≥–∏–¥', '–ø–µ—Ä–µ–≤–æ–¥—á–∏–∫-–≥–∏–¥', '—Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–≥–µ–Ω—Ç',
        '–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ç—É—Ä–∏–∑–º—É', '–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π',
        '–¥–µ–∫–æ—Ä–∞—Ç–æ—Ä', '–æ—Ñ–æ—Ä–º–∏—Ç–µ–ª—å', '–≤–∏—Ç—Ä–∏–Ω–∏—Å—Ç', '–º–µ—Ä—á–∞–Ω–¥–∞–π–∑–µ—Ä',
        '–¥–∏–∑–∞–π–Ω–µ—Ä –æ–¥–µ–∂–¥—ã', '–º–æ–¥–µ–ª—å–µ—Ä', '—Å—Ç–∏–ª–∏—Å—Ç', '–∏–º–∏–¥–∂–º–µ–π–∫–µ—Ä',
        '–≤–∏–∑–∞–∂–∏—Å—Ç', '–≥—Ä–∏–º–µ—Ä', '–ø–∞—Ä–∏–∫–º–∞—Ö–µ—Ä-—Å—Ç–∏–ª–∏—Å—Ç',
        '–º–∞—Å—Ç–µ—Ä –º–∞–Ω–∏–∫—é—Ä–∞', '–º–∞—Å—Ç–µ—Ä –ø–µ–¥–∏–∫—é—Ä–∞', '–∫–æ—Å–º–µ—Ç–æ–ª–æ–≥',
        '–º–∞—Å—Å–∞–∂–∏—Å—Ç', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–∞—Å—Å–∞–∂—É', '—Ä–µ—Ñ–ª–µ–∫—Å–æ—Ç–µ—Ä–∞–ø–µ–≤—Ç',
        '–∞—Ä–æ–º–∞—Ç–µ—Ä–∞–ø–µ–≤—Ç', '—ç—Å—Ç–µ—Ç–∏—Å—Ç', '–º–∞—Å—Ç–µ—Ä –ø–æ –Ω–∞—Ä–∞—â–∏–≤–∞–Ω–∏—é',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ç–∞—Ç—É–∞–∂—É', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–∏–∫—Ä–æ–±–ª–µ–π–¥–∏–Ω–≥—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–∞–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—é', '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–∞—à–º–µ–π–∫–∏–Ω–≥—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ø–µ—Ä–º–∞–Ω–µ–Ω—Ç–Ω–æ–º—É –º–∞–∫–∏—è–∂—É', '–º–∞—Å—Ç–µ—Ä –ø–æ –±—Ä–æ–≤—è–º',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ä–µ—Å–Ω–∏—Ü–∞–º', '–ª–∞—à–º–µ–π–∫–µ—Ä', '–±—Ä–æ–≤–∏—Å—Ç',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –Ω–æ–≥—Ç—è–º', '–Ω–µ–π–ª-–º–∞—Å—Ç–µ—Ä', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–∞–Ω–∏–∫—é—Ä—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ø–µ–¥–∏–∫—é—Ä—É', '–ø–æ–¥–æ–ª–æ–≥', '–º–∞—Å—Ç–µ—Ä –ø–æ —Å—Ç–æ–ø–∞–º',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ç–µ–ª—É', '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–∏—Ü—É', '—ç—Å—Ç–µ—Ç–∏—Å—Ç',
        '–∫–æ—Å–º–µ—Ç–æ–ª–æ–≥-—ç—Å—Ç–µ—Ç–∏—Å—Ç', '–¥–µ—Ä–º–∞—Ç–æ–ª–æ–≥', '—Ç—Ä–∏—Ö–æ–ª–æ–≥',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –≤–æ–ª–æ—Å–∞–º', '–∫–æ–ª–æ—Ä–∏—Å—Ç', '–º–∞—Å—Ç–µ—Ä –ø–æ –æ–∫—Ä–∞—à–∏–≤–∞–Ω–∏—é',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Å—Ç—Ä–∏–∂–∫–µ', '–±–∞—Ä–±–µ—Ä', '–º–∞—Å—Ç–µ—Ä –ø–æ –±–æ—Ä–æ–¥–µ',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —É—Å–∞–º', '–º–∞—Å—Ç–µ—Ä –ø–æ –±—Ä–∏—Ç—å—é', '–º–∞—Å—Ç–µ—Ä –ø–æ —É—Ö–æ–¥—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —É–∫–ª–∞–¥–∫–µ', '–º–∞—Å—Ç–µ—Ä –ø–æ –ø—Ä–∏—á–µ—Å–∫–∞–º', '—Å—Ç–∏–ª–∏—Å—Ç-–ø–∞—Ä–∏–∫–º–∞—Ö–µ—Ä',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –Ω–∞—Ä–∞—â–∏–≤–∞–Ω–∏—é –≤–æ–ª–æ—Å', '–º–∞—Å—Ç–µ—Ä –ø–æ –ø–ª–µ—Ç–µ–Ω–∏—é',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∞—Ñ—Ä–æ–∫–æ—Å–∏—á–∫–∞–º', '–º–∞—Å—Ç–µ—Ä –ø–æ –¥—Ä–µ–¥–∞–º',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–æ–∫–æ–Ω–∞–º', '–º–∞—Å—Ç–µ—Ä –ø–æ –∑–∞–≤–∏–≤–∫–µ', '–º–∞—Å—Ç–µ—Ä –ø–æ –≤—ã–ø—Ä—è–º–ª–µ–Ω–∏—é',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫–µ—Ä–∞—Ç–∏–Ω–æ–≤–æ–º—É –≤—ã–ø—Ä—è–º–ª–µ–Ω–∏—é', '–º–∞—Å—Ç–µ—Ä –ø–æ –±–æ—Ç–æ–∫—Å—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ñ–∏–ª–ª–µ—Ä–∞–º', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–µ–∑–æ—Ç–µ—Ä–∞–ø–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –±–∏–æ—Ä–µ–≤–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –ø–ª–∞–∑–º–æ–ª–∏—Ñ—Ç–∏–Ω–≥—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫–∞—Ä–±–æ–∫—Å–∏—Ç–µ—Ä–∞–ø–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –æ–∑–æ–Ω–æ—Ç–µ—Ä–∞–ø–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫—Ä–∏–æ—Ç–µ—Ä–∞–ø–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —É–ª—å—Ç—Ä–∞–∑–≤—É–∫—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ä–∞–¥–∏–æ—á–∞—Å—Ç–æ—Ç–Ω–æ–º—É –ª–∏—Ñ—Ç–∏–Ω–≥—É', '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–∞–∑–µ—Ä—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ñ–æ—Ç–æ–æ–º–æ–ª–æ–∂–µ–Ω–∏—é', '–º–∞—Å—Ç–µ—Ä –ø–æ IPL',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –¥–µ–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —à—É–≥–∞—Ä–∏–Ω–≥—É', '–º–∞—Å—Ç–µ—Ä –ø–æ –≤–æ—Å–∫–æ–≤–æ–π –¥–µ–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–∞–∑–µ—Ä–Ω–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —ç–ª–µ–∫—Ç—Ä–æ—ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ñ–æ—Ç–æ—ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —ç–ª–æ—Å-—ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ SHR-—ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ AFT-—ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –¥–∏–æ–¥–Ω–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –∞–ª–µ–∫—Å–∞–Ω–¥—Ä–∏—Ç–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ä—É–±–∏–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —Å–∞–ø—Ñ–∏—Ä–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –Ω–µ–æ–¥–∏–º–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —ç—Ä–±–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —É–≥–ª–µ–∫–∏—Å–ª–æ—Ç–Ω–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –æ–∫—Å–∏–¥–Ω–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∞–∑–æ—Ç–Ω–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –≥–µ–ª–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∞—Ä–≥–æ–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –∫—Å–µ–Ω–æ–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫—Ä–∏–ø—Ç–æ–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —Ä–∞–¥–æ–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ç–æ—Ä–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —É—Ä–∞–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ø–ª—É—Ç–æ–Ω–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –∞–º–µ—Ä–∏—Ü–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫—é—Ä–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –±–µ—Ä–∫–ª–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫–∞–ª–∏—Ñ–æ—Ä–Ω–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —ç–π–Ω—à—Ç–µ–π–Ω–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ñ–µ—Ä–º–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–µ–Ω–¥–µ–ª–µ–≤–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –Ω–æ–±–µ–ª–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–æ—É—Ä–µ–Ω—Å–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ä–µ–∑–µ—Ä—Ñ–æ—Ä–¥–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –¥—É–±–Ω–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Å–∏–±–æ—Ä–≥–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –±–æ—Ä–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ö–∞—Å—Å–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–µ–π—Ç–Ω–µ—Ä–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –¥–∞—Ä–º—à—Ç–∞–¥—Ç–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —Ä–µ–Ω—Ç–≥–µ–Ω–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫–æ–ø–µ—Ä–Ω–∏—Ü–∏–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —Ñ–ª–µ—Ä–æ–≤–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–∏–≤–µ—Ä–º–æ—Ä–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –æ–≥–∞–Ω–µ—Å—Å–æ–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ç–µ–Ω–Ω–µ—Å—Å–∏–Ω–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–æ—Å–∫–æ–≤–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏'
    ]
    
    def __init__(self, db_path: str = "geekjob_vacancies.db", delay: float = 1.0, timeout: int = 30):
        self.db = VacancyDatabase(db_path)
        self.delay = delay
        self.timeout = timeout
        self.session = self._create_session()
        
    def _create_session(self) -> requests.Session:
        """–°–æ–∑–¥–∞–Ω–∏–µ HTTP —Å–µ—Å—Å–∏–∏ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })
        return session
    
    def is_relevant_vacancy(self, title: str, description: str = '') -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –¥–∏–∑–∞–π–Ω–µ—Ä–æ–≤"""
        text = f"{title} {description}".lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–∏–∑–∞–π–Ω–∞
        has_design_keywords = any(keyword.lower() in text for keyword in self.DESIGN_KEYWORDS)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∏—Å–∫–ª—é—á–∞—é—â–∏—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        has_excluded_keywords = any(keyword.lower() in text for keyword in self.EXCLUDED_KEYWORDS)
        
        # –í–∞–∫–∞–Ω—Å–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞, –µ—Å–ª–∏ –µ—Å—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–∏–∑–∞–π–Ω–∞ –ò –Ω–µ—Ç –∏—Å–∫–ª—é—á–∞—é—â–∏—Ö
        return has_design_keywords and not has_excluded_keywords
    
    def extract_vacancy_id(self, url: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–∑ URL"""
        if '/vacancy/' in url:
            return url.split('/vacancy/')[-1].split('?')[0].split('/')[0]
        return url.split('/')[-1].split('?')[0]
    
    def parse_vacancy_list_page(self, query: str, page: int = 1) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–æ —Å–ø–∏—Å–∫–æ–º –≤–∞–∫–∞–Ω—Å–∏–π"""
        url = f"https://geekjob.ru/vacancies?q={quote(query)}&page={page}"
        
        try:
            logging.info(f"üîç –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {url}")
            
            response = self.session.get(url, timeout=self.timeout)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏–∏
            vacancy_links = soup.find_all('a', href=lambda x: x and '/vacancy/' in x)
            
            if not vacancy_links:
                logging.warning(f"‚ö†Ô∏è –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏–∏")
                return []
            
            logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(vacancy_links)} —Å—Å—ã–ª–æ–∫ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏–∏")
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å—Å—ã–ª–∫–∏ –ø–æ ID –≤–∞–∫–∞–Ω—Å–∏–∏
            vacancies_data = {}
            
            for link in vacancy_links:
                try:
                    href = link.get('href', '')
                    text = link.get_text(strip=True)
                    
                    if not href or not text:
                        continue
                    
                    vacancy_id = self.extract_vacancy_id(href)
                    if not vacancy_id:
                        continue
                    
                    full_url = urljoin('https://geekjob.ru', href)
                    
                    if vacancy_id not in vacancies_data:
                        vacancies_data[vacancy_id] = {
                            'external_id': f"geekjob-{vacancy_id}",
                            'url': full_url,
                            'title': '',
                            'company': '',
                            'salary': '',
                            'location': '',
                            'description': ''
                        }
                    
                    vacancy = vacancies_data[vacancy_id]
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
                    if any(currency in text for currency in ['‚ÇΩ', '‚Ç¨', '$', '—Ä—É–±']):
                        vacancy['salary'] = text
                    elif len(text) > 50 and not any(word in text.lower() for word in ['remote', 'office', '–º–æ—Å–∫–≤–∞', '—Å–ø–±']):
                        if not vacancy['title']:
                            vacancy['title'] = text
                        elif not vacancy['description']:
                            vacancy['description'] = text
                    elif len(text) < 50 and not any(currency in text for currency in ['‚ÇΩ', '‚Ç¨', '$']):
                        if not vacancy['company']:
                            vacancy['company'] = text
                    elif any(location in text.lower() for location in ['–º–æ—Å–∫–≤–∞', '—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥', 'remote', '—É–¥–∞–ª–µ–Ω–Ω–æ']):
                        vacancy['location'] = text
                
                except Exception as e:
                    logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Å—ã–ª–∫–∏: {e}")
                    continue
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏
            relevant_vacancies = []
            for vacancy_id, vacancy in vacancies_data.items():
                if vacancy['title'] and self.is_relevant_vacancy(vacancy['title'], vacancy['description']):
                    relevant_vacancies.append(vacancy)
                    logging.info(f"‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –≤–∞–∫–∞–Ω—Å–∏—è: {vacancy['title']}")
                else:
                    logging.debug(f"‚ùå –ù–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –≤–∞–∫–∞–Ω—Å–∏—è: {vacancy.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
            
            return relevant_vacancies
            
        except requests.RequestException as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ HTTP –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
            return []
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
            return []
    
    def extract_full_vacancy_details(self, vacancy_url: str) -> Dict[str, str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            logging.debug(f"üîç –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–µ—Ç–∞–ª–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {vacancy_url}")
            
            response = self.session.get(vacancy_url, timeout=self.timeout)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º
            description_selectors = [
                '.vacancy-description',
                '.job-description', 
                '.description',
                '.vacancy-content',
                '.job-content',
                '.content',
                '[class*="description"]',
                '[class*="content"]'
            ]
            
            full_description = ''
            for selector in description_selectors:
                element = soup.select_one(selector)
                if element:
                    text = element.get_text(strip=True)
                    if text and len(text) > 100:
                        full_description = text
                        logging.debug(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä {selector}: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                        break
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã, –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if not full_description:
                page_text = soup.get_text()
                # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –±–ª–æ–∫–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º
                lines = page_text.split('\n')
                description_lines = []
                in_description = False
                
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                    
                    if any(keyword in line.lower() for keyword in ['–æ–ø–∏—Å–∞–Ω–∏–µ', '–æ –≤–∞–∫–∞–Ω—Å–∏–∏', '—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è']):
                        in_description = True
                        continue
                    
                    if in_description:
                        if len(line) > 20:
                            description_lines.append(line)
                        if len(description_lines) > 20:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
                            break
                
                if description_lines:
                    full_description = '\n'.join(description_lines)
                    logging.debug(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ —á–µ—Ä–µ–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫: {len(full_description)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∏
            def extract_section(keywords: List[str]) -> str:
                for keyword in keywords:
                    # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å–µ–∫—Ü–∏–π
                    headers = soup.find_all(['h1', 'h2', 'h3', 'h4', 'strong', 'b'], 
                                          string=lambda text: text and keyword.lower() in text.lower())
                    
                    for header in headers:
                        # –ò—â–µ–º —Å–ª–µ–¥—É—é—â–∏–π —ç–ª–µ–º–µ–Ω—Ç —Å —Ç–µ–∫—Å—Ç–æ–º
                        next_elem = header.find_next_sibling()
                        if next_elem:
                            text = next_elem.get_text(strip=True)
                            if text and len(text) > 20:
                                return text
                
                # –ü–æ–∏—Å–∫ –≤ —Ç–µ–∫—Å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏—è
                if full_description:
                    for keyword in keywords:
                        pattern = f"{keyword}.*?(?=(?:{'|'.join(['—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è', '–∑–∞–¥–∞—á–∏', '—É—Å–ª–æ–≤–∏—è', '–ª—å–≥–æ—Ç—ã', '–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏'])})|$)"
                        import re
                        match = re.search(pattern, full_description, re.IGNORECASE | re.DOTALL)
                        if match:
                            return match.group(0).strip()
                
                return ''
            
            requirements = extract_section(['—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è', '–æ–∂–∏–¥–∞–Ω–∏—è', '–Ω—É–∂–Ω–æ', '–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ'])
            tasks = extract_section(['–∑–∞–¥–∞—á–∏', '–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏', '—Ñ—É–Ω–∫—Ü–∏–∏', '—á—Ç–æ –¥–µ–ª–∞—Ç—å'])
            benefits = extract_section(['–º—ã –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º', '–ª—å–≥–æ—Ç—ã', '–ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞', '–±–æ–Ω—É—Å—ã'])
            conditions = extract_section(['—É—Å–ª–æ–≤–∏—è', '—á—Ç–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º', '—Ñ–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã'])
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º simple_text_formatter –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            formatted_description = extract_formatted_text(full_description) if full_description else '–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'
            
            return {
                'full_description': formatted_description,
                'requirements': '',  # –ù–µ —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–ª–æ–∫–∏
                'tasks': '',
                'benefits': '',
                'conditions': ''
            }
            
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π –≤–∞–∫–∞–Ω—Å–∏–∏ {vacancy_url}: {e}")
            return {
                'full_description': '–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ',
                'requirements': '',
                'tasks': '',
                'benefits': '',
                'conditions': ''
            }
    
    def parse_vacancies(self, query: str = '–¥–∏–∑–∞–π–Ω–µ—Ä', pages: int = 10, extract_details: bool = True) -> List[Dict[str, Any]]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–π"""
        logging.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ Geekjob.ru")
        logging.info(f"üîç –ó–∞–ø—Ä–æ—Å: '{query}', —Å—Ç—Ä–∞–Ω–∏—Ü: {pages}, –¥–µ—Ç–∞–ª–∏: {extract_details}")
        
        all_vacancies = []
        
        for page in range(1, pages + 1):
            try:
                # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–æ —Å–ø–∏—Å–∫–æ–º
                page_vacancies = self.parse_vacancy_list_page(query, page)
                
                if not page_vacancies:
                    logging.warning(f"‚ö†Ô∏è –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π")
                    continue
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–µ—Ç–∞–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏
                for vacancy in page_vacancies:
                    try:
                        if extract_details:
                            details = self.extract_full_vacancy_details(vacancy['url'])
                            vacancy.update(details)
                        
                        # –û—á–∏—â–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏
                        vacancy = clean_vacancy_data(vacancy)
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                        vacancy['source'] = 'geekjob'
                        vacancy['published_at'] = datetime.now().isoformat()
                        vacancy['status'] = 'pending'
                        
                        all_vacancies.append(vacancy)
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                        self.db.save_vacancy(vacancy)
                        
                        # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                        if extract_details:
                            time.sleep(self.delay)
                        
                    except Exception as e:
                        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
                        continue
                
                logging.info(f"üìä –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –Ω–∞–π–¥–µ–Ω–æ {len(page_vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π")
                
                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
                time.sleep(self.delay)
                
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
                continue
        
        logging.info(f"üéØ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω. –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(all_vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π")
        return all_vacancies
    
    def export_to_json(self, filename: str = 'geekjob_vacancies.json'):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤–∞–∫–∞–Ω—Å–∏–π –≤ JSON"""
        try:
            with sqlite3.connect(self.db.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM vacancies WHERE source = 'geekjob'")
                
                columns = [description[0] for description in cursor.description]
                rows = cursor.fetchall()
                
                vacancies = []
                for row in rows:
                    vacancy = dict(zip(columns, row))
                    vacancies.append(vacancy)
                
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(vacancies, f, ensure_ascii=False, indent=2, default=str)
                
                logging.info(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON –∑–∞–≤–µ—Ä—à—ë–Ω: {filename} ({len(vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π)")
                return True
                
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ JSON: {e}")
            return False
    
    def export_to_csv(self, filename: str = 'geekjob_vacancies.csv'):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤–∞–∫–∞–Ω—Å–∏–π –≤ CSV"""
        try:
            import csv
            
            with sqlite3.connect(self.db.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM vacancies WHERE source = 'geekjob'")
                
                columns = [description[0] for description in cursor.description]
                rows = cursor.fetchall()
                
                with open(filename, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(columns)
                    writer.writerows(rows)
                
                logging.info(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV –∑–∞–≤–µ—Ä—à—ë–Ω: {filename} ({len(rows)} –≤–∞–∫–∞–Ω—Å–∏–π)")
                return True
                
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ CSV: {e}")
            return False


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–ü–∞—Ä—Å–µ—Ä –≤–∞–∫–∞–Ω—Å–∏–π Geekjob.ru –¥–ª—è –¥–∏–∑–∞–π–Ω–µ—Ä–æ–≤')
    
    parser.add_argument('--db', default='geekjob_vacancies.db', help='–ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--query', default='–¥–∏–∑–∞–π–Ω–µ—Ä', help='–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å')
    parser.add_argument('--pages', type=int, default=10, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞')
    parser.add_argument('--delay', type=float, default=1.0, help='–ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—Å–µ–∫)')
    parser.add_argument('--timeout', type=int, default=30, help='–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (—Å–µ–∫)')
    parser.add_argument('--verbose', action='store_true', help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥')
    parser.add_argument('--quiet', action='store_true', help='–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥')
    parser.add_argument('--export', choices=['json', 'csv'], help='–≠–∫—Å–ø–æ—Ä—Ç –≤ —Ñ–æ—Ä–º–∞—Ç')
    parser.add_argument('--no-details', action='store_true', help='–ù–µ –∏–∑–≤–ª–µ–∫–∞—Ç—å –ø–æ–ª–Ω—ã–µ –¥–µ—Ç–∞–ª–∏')
    parser.add_argument('--dry-run', action='store_true', help='–¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è')
    
    args = parser.parse_args()
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    log_level = not args.quiet if not args.verbose else args.verbose
    logger = setup_logging(verbose=log_level)
    
    try:
        # –°–æ–∑–¥–∞—ë–º –ø–∞—Ä—Å–µ—Ä
        geekjob = GeekjobParser(
            db_path=args.db,
            delay=args.delay,
            timeout=args.timeout
        )
        
        if args.dry_run:
            logging.info("üß™ –¢–ï–°–¢–û–í–´–ô –†–ï–ñ–ò–ú - –¥–∞–Ω–Ω—ã–µ –Ω–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥
        vacancies = geekjob.parse_vacancies(
            query=args.query,
            pages=args.pages,
            extract_details=not args.no_details
        )
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if not args.dry_run:
            stats = geekjob.db.get_statistics()
            logging.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:")
            logging.info(f"   –í—Å–µ–≥–æ –≤–∞–∫–∞–Ω—Å–∏–π: {stats.get('total', 0)}")
            logging.info(f"   –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24—á: {stats.get('last_24h', 0)}")
            logging.info(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π: {stats.get('unique_companies', 0)}")
        
        # –≠–∫—Å–ø–æ—Ä—Ç
        if args.export and not args.dry_run:
            if args.export == 'json':
                geekjob.export_to_json()
            elif args.export == 'csv':
                geekjob.export_to_csv()
        
        logging.info("üéâ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ!")
        return 0
        
    except KeyboardInterrupt:
        logging.info("‚ö†Ô∏è –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return 1
    except Exception as e:
        logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())



