#!/usr/bin/env python3
"""
HireHi –ø–∞—Ä—Å–µ—Ä –Ω–∞ Python –¥–ª—è –¥–∏–∑–∞–π–Ω–µ—Ä—Å–∫–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π

–í–µ—Ä—Å–∏—è: 1.0.0
–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 2025-01-02
"""

import os
import sys
import time
import json
import logging
import requests
from datetime import datetime
from urllib.parse import urljoin, quote
from bs4 import BeautifulSoup
from typing import List, Dict, Optional, Any
try:
    from simple_text_formatter import extract_formatted_text, clean_text
    from text_cleaner import clean_vacancy_data
    from anti_detection_system import AntiDetectionSystem, RequestMethod
    from blocking_monitor import log_blocking_event, log_success_event
    from hirehi_bypass import get_hirehi_page, test_hirehi_access
    from playwright_bypass import get_page_with_playwright_sync
except ImportError:
    # Fallback –¥–ª—è —Å–ª—É—á–∞—è, –∫–æ–≥–¥–∞ –º–æ–¥—É–ª—å –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é
    import sys
    import os
    sys.path.append(os.path.dirname(__file__))
    from simple_text_formatter import extract_formatted_text, clean_text
    from text_cleaner import clean_vacancy_data
    try:
        from anti_detection_system import AntiDetectionSystem, RequestMethod
        from blocking_monitor import log_blocking_event, log_success_event
        from hirehi_bypass import get_hirehi_page, test_hirehi_access
        from playwright_bypass import get_page_with_playwright_sync
    except ImportError:
        AntiDetectionSystem = None
        RequestMethod = None
        log_blocking_event = None
        log_success_event = None
        get_hirehi_page = None
        test_hirehi_access = None
        get_page_with_playwright_sync = None


class HireHiParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è HireHi.com"""
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–∏–∑–∞–π–Ω–µ—Ä—Å–∫–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π
    DESIGN_KEYWORDS = [
        '–¥–∏–∑–∞–π–Ω', '–¥–∏–∑–∞–π–Ω–µ—Ä', '–¥–∏–∑–∞–π–Ω–µ—Ä –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤', 'ui/ux', 'ux/ui', '–ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –¥–∏–∑–∞–π–Ω',
        '—Ü–∏—Ñ—Ä–æ–≤–æ–π –¥–∏–∑–∞–π–Ω', '–≤–µ–±-–¥–∏–∑–∞–π–Ω', '–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–Ω—ã–π –¥–∏–∑–∞–π–Ω', '–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –¥–∏–∑–∞–π–Ω',
        '–≤–∏–∑—É–∞–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω', '–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∏–∑–∞–π–Ω', 'user experience',
        'user interface', 'ux-–¥–∏–∑–∞–π–Ω–µ—Ä', 'ui-–¥–∏–∑–∞–π–Ω–µ—Ä', '–ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –¥–∏–∑–∞–π–Ω–µ—Ä',
        'designer', 'ui designer', 'ux designer', 'product designer', 'visual designer'
    ]
    
    # –ò—Å–∫–ª—é—á–µ–Ω–∏—è - –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ç–∏–ø—ã –¥–∏–∑–∞–π–Ω–∞
    EXCLUDED_KEYWORDS = [
        '—Ç–µ–∫—Å—Ç–∏–ª—å', '—Ç–µ–∫—Å—Ç–∏–ª—å–Ω—ã–π', '—Ç–∫–∞–Ω—å', '–æ–¥–µ–∂–¥–∞', '–º–æ–¥–∞', 'fashion',
        '—é–≤–µ–ª–∏—Ä–Ω—ã–π', '—é–≤–µ–ª–∏—Ä', '—É–∫—Ä–∞—à–µ–Ω–∏—è', '–±–∏–∂—É—Ç–µ—Ä–∏—è',
        '–º–µ–±–µ–ª—å', '–∏–Ω—Ç–µ—Ä—å–µ—Ä', '–¥–µ–∫–æ—Ä', '–ª–∞–Ω–¥—à–∞—Ñ—Ç', '—Å–∞–¥–æ–≤—ã–π',
        '–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π', '–º–∞—à–∏–Ω–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ', '–∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π',
        '—É–ø–∞–∫–æ–≤–∫–∞', '–ø–æ–ª–∏–≥—Ä–∞—Ñ–∏—è', '–ø–µ—á–∞—Ç—å', '—Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏—è',
        '–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π', '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π', '—Ä–µ—Å—Ç–∞–≤—Ä–∞—Ü–∏—è',
        '–∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–π', '–ø–∞—Ä–∏–∫–º–∞—Ö–µ—Ä', '–º–∞–Ω–∏–∫—é—Ä', '–ø–µ–¥–∏–∫—é—Ä',
        '–∫—É–ª–∏–Ω–∞—Ä–Ω—ã–π', '–∫–æ–Ω–¥–∏—Ç–µ—Ä', '–ø–æ–≤–∞—Ä', '—à–µ—Ñ-–ø–æ–≤–∞—Ä',
        '—Ñ–ª–æ—Ä–∏—Å—Ç–∏–∫–∞', '—Ü–≤–µ—Ç—ã', '–±—É–∫–µ—Ç', '—Å–≤–∞–¥–µ–±–Ω—ã–π',
        '—Ç–∞—Ç—É', '—Ç–∞—Ç—É–∏—Ä–æ–≤–∫–∞', '–ø–∏—Ä—Å–∏–Ω–≥', '–±–æ–¥–∏-–∞—Ä—Ç',
        '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ', '—Ñ–æ—Ç–æ', '–≤–∏–¥–µ–æ', '–º–æ–Ω—Ç–∞–∂',
        '–∑–≤—É–∫', '–∞—É–¥–∏–æ', '–º—É–∑—ã–∫–∞', '–∫–æ–º–ø–æ–∑–∏—Ç–æ—Ä',
        '—Ç–∞–Ω—Ü—ã', '—Ö–æ—Ä–µ–æ–≥—Ä–∞—Ñ', '–±–∞–ª–µ—Ç', '—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ç–∞–Ω–µ—Ü',
        '–∞–∫—Ç–µ—Ä', '–∞–∫—Ç—Ä–∏—Å–∞', '—Ç–µ–∞—Ç—Ä', '–∫–∏–Ω–æ',
        '–ø–∏—Å–∞—Ç–µ–ª—å', '–∂—É—Ä–Ω–∞–ª–∏—Å—Ç', '–∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä', '—Ä–µ–¥–∞–∫—Ç–æ—Ä',
        '–ø–µ—Ä–µ–≤–æ–¥—á–∏–∫', '–ª–∏–Ω–≥–≤–∏—Å—Ç', '—Ñ–∏–ª–æ–ª–æ–≥',
        '–ø—Å–∏—Ö–æ–ª–æ–≥', '–ø—Å–∏—Ö–æ—Ç–µ—Ä–∞–ø–µ–≤—Ç', '–∫–æ—É—á',
        '—Ç—Ä–µ–Ω–µ—Ä', '—Ñ–∏—Ç–Ω–µ—Å', '–π–æ–≥–∞', '–ø–∏–ª–∞—Ç–µ—Å',
        '–º–∞—Å—Å–∞–∂', '–º–∞—Å—Å–∞–∂–∏—Å—Ç', '—Å–ø–∞', '—Å–∞–ª–æ–Ω',
        '–ø—Ä–æ–¥–∞–≤–µ—Ü', '–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç', '–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º',
        '–≤–æ–¥–∏—Ç–µ–ª—å', '–∫—É—Ä—å–µ—Ä', '–ª–æ–≥–∏—Å—Ç', '—Å–∫–ª–∞–¥',
        '–æ—Ö—Ä–∞–Ω–∞', '–æ—Ö—Ä–∞–Ω–Ω–∏–∫', '—Å–µ–∫—Ä–µ—Ç–∞—Ä—å', '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä',
        '—É–±–æ—Ä—â–∏–∫', '—É–±–æ—Ä—â–∏—Ü–∞', '–¥–≤–æ—Ä–Ω–∏–∫', '—Å–∞–¥–æ–≤–Ω–∏–∫',
        '—ç–ª–µ–∫—Ç—Ä–∏–∫', '—Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫', '—Å–ª–µ—Å–∞—Ä—å', '–º–µ—Ö–∞–Ω–∏–∫',
        '—Å–≤–∞—Ä—â–∏–∫', '—Ç–æ–∫–∞—Ä—å', '—Ñ—Ä–µ–∑–µ—Ä–æ–≤—â–∏–∫', '—Å–ª–µ—Å–∞—Ä—å-—Å–±–æ—Ä—â–∏–∫',
        '–º–∞–ª—è—Ä', '—à—Ç—É–∫–∞—Ç—É—Ä', '–ø–ª–∏—Ç–æ—á–Ω–∏–∫', '–∫–∞–º–µ–Ω—â–∏–∫',
        '—Å—Ç–æ–ª—è—Ä', '–ø–ª–æ—Ç–Ω–∏–∫', '–∫—Ä–∞—Å–Ω–æ–¥–µ—Ä–µ–≤—â–∏–∫', '–º–µ–±–µ–ª—å—â–∏–∫',
        '—à–≤–µ—è', '–ø–æ—Ä—Ç–Ω–æ–π', '–∑–∞–∫—Ä–æ–π—â–∏–∫', '–º–æ–¥–µ–ª—å–µ—Ä',
        '–æ–±—É–≤—â–∏–∫', '—Å–∞–ø–æ–∂–Ω–∏–∫', '–∫–æ–∂–µ–≤–Ω–∏–∫', '—Å–∫–æ—Ä–Ω—è–∫',
        '—é–≤–µ–ª–∏—Ä', '–≥—Ä–∞–≤–µ—Ä', '—á–µ–∫–∞–Ω—â–∏–∫', '–ª–∏—Ç–µ–π—â–∏–∫',
        '—Å—Ç–µ–∫–ª–æ–¥—É–≤', '–∫–µ—Ä–∞–º–∏—Å—Ç', '–≥–æ–Ω—á–∞—Ä', '—Å–∫—É–ª—å–ø—Ç–æ—Ä',
        '—Ö—É–¥–æ–∂–Ω–∏–∫', '–∂–∏–≤–æ–ø–∏—Å–µ—Ü', '–≥—Ä–∞—Ñ–∏–∫', '–∏–ª–ª—é—Å—Ç—Ä–∞—Ç–æ—Ä',
        '–∫–∞–ª–ª–∏–≥—Ä–∞—Ñ', '—à—Ä–∏—Ñ—Ç–æ–≤–∏–∫', '—Ç–∏–ø–æ–≥—Ä–∞—Ñ', '–ø–µ—á–∞—Ç–Ω–∏–∫',
        '–ø–µ—Ä–µ–ø–ª–µ—Ç—á–∏–∫', '—Ä–µ—Å—Ç–∞–≤—Ä–∞—Ç–æ—Ä –∫–Ω–∏–≥', '–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å',
        '–∞—Ä—Ö–∏–≤–∞—Ä–∏—É—Å', '–º—É–∑–µ–π–Ω—ã–π —Ä–∞–±–æ—Ç–Ω–∏–∫', '—ç–∫—Å–∫—É—Ä—Å–æ–≤–æ–¥',
        '–≥–∏–¥', '–ø–µ—Ä–µ–≤–æ–¥—á–∏–∫-–≥–∏–¥', '—Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–≥–µ–Ω—Ç',
        '–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ç—É—Ä–∏–∑–º—É', '–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π',
        '–¥–µ–∫–æ—Ä–∞—Ç–æ—Ä', '–æ—Ñ–æ—Ä–º–∏—Ç–µ–ª—å', '–≤–∏—Ç—Ä–∏–Ω–∏—Å—Ç', '–º–µ—Ä—á–∞–Ω–¥–∞–π–∑–µ—Ä',
        '–¥–∏–∑–∞–π–Ω–µ—Ä –æ–¥–µ–∂–¥—ã', '–º–æ–¥–µ–ª—å–µ—Ä', '—Å—Ç–∏–ª–∏—Å—Ç', '–∏–º–∏–¥–∂–º–µ–π–∫–µ—Ä',
        '–≤–∏–∑–∞–∂–∏—Å—Ç', '–≥—Ä–∏–º–µ—Ä', '–ø–∞—Ä–∏–∫–º–∞—Ö–µ—Ä-—Å—Ç–∏–ª–∏—Å—Ç',
        '–º–∞—Å—Ç–µ—Ä –º–∞–Ω–∏–∫—é—Ä–∞', '–º–∞—Å—Ç–µ—Ä –ø–µ–¥–∏–∫—é—Ä–∞', '–∫–æ—Å–º–µ—Ç–æ–ª–æ–≥',
        '–º–∞—Å—Å–∞–∂–∏—Å—Ç', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–∞—Å—Å–∞–∂—É', '—Ä–µ—Ñ–ª–µ–∫—Å–æ—Ç–µ—Ä–∞–ø–µ–≤—Ç',
        '–∞—Ä–æ–º–∞—Ç–µ—Ä–∞–ø–µ–≤—Ç', '—ç—Å—Ç–µ—Ç–∏—Å—Ç', '–º–∞—Å—Ç–µ—Ä –ø–æ –Ω–∞—Ä–∞—â–∏–≤–∞–Ω–∏—é',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ç–∞—Ç—É–∞–∂—É', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–∏–∫—Ä–æ–±–ª–µ–π–¥–∏–Ω–≥—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–∞–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—é', '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–∞—à–º–µ–π–∫–∏–Ω–≥—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ø–µ—Ä–º–∞–Ω–µ–Ω—Ç–Ω–æ–º—É –º–∞–∫–∏—è–∂—É', '–º–∞—Å—Ç–µ—Ä –ø–æ –±—Ä–æ–≤—è–º',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ä–µ—Å–Ω–∏—Ü–∞–º', '–ª–∞—à–º–µ–π–∫–µ—Ä', '–±—Ä–æ–≤–∏—Å—Ç',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –Ω–æ–≥—Ç—è–º', '–Ω–µ–π–ª-–º–∞—Å—Ç–µ—Ä', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–∞–Ω–∏–∫—é—Ä—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ø–µ–¥–∏–∫—é—Ä—É', '–ø–æ–¥–æ–ª–æ–≥', '–º–∞—Å—Ç–µ—Ä –ø–æ —Å—Ç–æ–ø–∞–º',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ç–µ–ª—É', '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–∏—Ü—É', '—ç—Å—Ç–µ—Ç–∏—Å—Ç',
        '–∫–æ—Å–º–µ—Ç–æ–ª–æ–≥-—ç—Å—Ç–µ—Ç–∏—Å—Ç', '–¥–µ—Ä–º–∞—Ç–æ–ª–æ–≥', '—Ç—Ä–∏—Ö–æ–ª–æ–≥',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –≤–æ–ª–æ—Å–∞–º', '–∫–æ–ª–æ—Ä–∏—Å—Ç', '–º–∞—Å—Ç–µ—Ä –ø–æ –æ–∫—Ä–∞—à–∏–≤–∞–Ω–∏—é',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Å—Ç—Ä–∏–∂–∫–µ', '–±–∞—Ä–±–µ—Ä', '–º–∞—Å—Ç–µ—Ä –ø–æ –±–æ—Ä–æ–¥–µ',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —É—Å–∞–º', '–º–∞—Å—Ç–µ—Ä –ø–æ –±—Ä–∏—Ç—å—é', '–º–∞—Å—Ç–µ—Ä –ø–æ —É—Ö–æ–¥—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —É–∫–ª–∞–¥–∫–µ', '–º–∞—Å—Ç–µ—Ä –ø–æ –ø—Ä–∏—á–µ—Å–∫–∞–º', '—Å—Ç–∏–ª–∏—Å—Ç-–ø–∞—Ä–∏–∫–º–∞—Ö–µ—Ä',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –Ω–∞—Ä–∞—â–∏–≤–∞–Ω–∏—é –≤–æ–ª–æ—Å', '–º–∞—Å—Ç–µ—Ä –ø–æ –ø–ª–µ—Ç–µ–Ω–∏—é',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∞—Ñ—Ä–æ–∫–æ—Å–∏—á–∫–∞–º', '–º–∞—Å—Ç–µ—Ä –ø–æ –¥—Ä–µ–¥–∞–º',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–æ–∫–æ–Ω–∞–º', '–º–∞—Å—Ç–µ—Ä –ø–æ –∑–∞–≤–∏–≤–∫–µ', '–º–∞—Å—Ç–µ—Ä –ø–æ –≤—ã–ø—Ä—è–º–ª–µ–Ω–∏—é',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫–µ—Ä–∞—Ç–∏–Ω–æ–≤–æ–º—É –≤—ã–ø—Ä—è–º–ª–µ–Ω–∏—é', '–º–∞—Å—Ç–µ—Ä –ø–æ –±–æ—Ç–æ–∫—Å—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ñ–∏–ª–ª–µ—Ä–∞–º', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–µ–∑–æ—Ç–µ—Ä–∞–ø–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –±–∏–æ—Ä–µ–≤–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –ø–ª–∞–∑–º–æ–ª–∏—Ñ—Ç–∏–Ω–≥—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫–∞—Ä–±–æ–∫—Å–∏—Ç–µ—Ä–∞–ø–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –æ–∑–æ–Ω–æ—Ç–µ—Ä–∞–ø–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫—Ä–∏–æ—Ç–µ—Ä–∞–ø–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —É–ª—å—Ç—Ä–∞–∑–≤—É–∫—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ä–∞–¥–∏–æ—á–∞—Å—Ç–æ—Ç–Ω–æ–º—É –ª–∏—Ñ—Ç–∏–Ω–≥—É', '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–∞–∑–µ—Ä—É',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ñ–æ—Ç–æ–æ–º–æ–ª–æ–∂–µ–Ω–∏—é', '–º–∞—Å—Ç–µ—Ä –ø–æ IPL',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –¥–µ–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —à—É–≥–∞—Ä–∏–Ω–≥—É', '–º–∞—Å—Ç–µ—Ä –ø–æ –≤–æ—Å–∫–æ–≤–æ–π –¥–µ–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–∞–∑–µ—Ä–Ω–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —ç–ª–µ–∫—Ç—Ä–æ—ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ñ–æ—Ç–æ—ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —ç–ª–æ—Å-—ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ SHR-—ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ AFT-—ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –¥–∏–æ–¥–Ω–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –∞–ª–µ–∫—Å–∞–Ω–¥—Ä–∏—Ç–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ä—É–±–∏–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —Å–∞–ø—Ñ–∏—Ä–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –Ω–µ–æ–¥–∏–º–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —ç—Ä–±–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —É–≥–ª–µ–∫–∏—Å–ª–æ—Ç–Ω–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –æ–∫—Å–∏–¥–Ω–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∞–∑–æ—Ç–Ω–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –≥–µ–ª–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∞—Ä–≥–æ–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –∫—Å–µ–Ω–æ–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫—Ä–∏–ø—Ç–æ–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —Ä–∞–¥–æ–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ç–æ—Ä–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —É—Ä–∞–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ø–ª—É—Ç–æ–Ω–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –∞–º–µ—Ä–∏—Ü–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫—é—Ä–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –±–µ—Ä–∫–ª–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫–∞–ª–∏—Ñ–æ—Ä–Ω–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —ç–π–Ω—à—Ç–µ–π–Ω–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ñ–µ—Ä–º–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–µ–Ω–¥–µ–ª–µ–≤–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –Ω–æ–±–µ–ª–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–æ—É—Ä–µ–Ω—Å–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ä–µ–∑–µ—Ä—Ñ–æ—Ä–¥–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –¥—É–±–Ω–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Å–∏–±–æ—Ä–≥–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –±–æ—Ä–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ö–∞—Å—Å–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–µ–π—Ç–Ω–µ—Ä–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –¥–∞—Ä–º—à—Ç–∞–¥—Ç–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —Ä–µ–Ω—Ç–≥–µ–Ω–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –∫–æ–ø–µ—Ä–Ω–∏—Ü–∏–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ —Ñ–ª–µ—Ä–æ–≤–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ –ª–∏–≤–µ—Ä–º–æ—Ä–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –æ–≥–∞–Ω–µ—Å—Å–æ–Ω–æ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏',
        '–º–∞—Å—Ç–µ—Ä –ø–æ —Ç–µ–Ω–Ω–µ—Å—Å–∏–Ω–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏', '–º–∞—Å—Ç–µ—Ä –ø–æ –º–æ—Å–∫–æ–≤–∏–µ–≤–æ–π —ç–ø–∏–ª—è—Ü–∏–∏'
    ]
    
    def __init__(self, delay: float = 1.0, timeout: int = 30):
        self.delay = delay
        self.timeout = timeout
        self.session = self._create_session()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω—Ç–∏–¥–µ—Ç–µ–∫—Ç —Å–∏—Å—Ç–µ–º—É
        if AntiDetectionSystem:
            self.anti_detection = AntiDetectionSystem()
            logging.info("üõ°Ô∏è –ê–Ω—Ç–∏–¥–µ—Ç–µ–∫—Ç —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è HireHi")
        else:
            self.anti_detection = None
            logging.warning("‚ö†Ô∏è –ê–Ω—Ç–∏–¥–µ—Ç–µ–∫—Ç —Å–∏—Å—Ç–µ–º–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è HireHi")
        
    def _create_session(self) -> requests.Session:
        """–°–æ–∑–¥–∞–Ω–∏–µ HTTP —Å–µ—Å—Å–∏–∏ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br, zstd',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0',
            'DNT': '1',
            'Sec-Ch-Ua': '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': '"Windows"'
        })
        return session
    
    def is_relevant_vacancy(self, title: str, description: str = '') -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –¥–∏–∑–∞–π–Ω–µ—Ä–æ–≤"""
        text = f"{title} {description}".lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–∏–∑–∞–π–Ω–∞
        has_design_keywords = any(keyword.lower() in text for keyword in self.DESIGN_KEYWORDS)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∏—Å–∫–ª—é—á–∞—é—â–∏—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        has_excluded_keywords = any(keyword.lower() in text for keyword in self.EXCLUDED_KEYWORDS)
        
        # –í–∞–∫–∞–Ω—Å–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞, –µ—Å–ª–∏ –µ—Å—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–∏–∑–∞–π–Ω–∞ –ò –Ω–µ—Ç –∏—Å–∫–ª—é—á–∞—é—â–∏—Ö
        return has_design_keywords and not has_excluded_keywords
    
    def extract_vacancy_id(self, url: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–∑ URL"""
        if '/job/' in url:
            return url.split('/job/')[-1].split('?')[0].split('/')[0]
        elif '/vacancy/' in url:
            return url.split('/vacancy/')[-1].split('?')[0].split('/')[0]
        return url.split('/')[-1].split('?')[0]
    
    def parse_vacancy_list_page(self, query: str, page: int = 1) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–æ —Å–ø–∏—Å–∫–æ–º –≤–∞–∫–∞–Ω—Å–∏–π HireHi"""
        url = f"https://hirehi.com/jobs?q={quote(query)}&page={page}"
        
        try:
            logging.info(f"–ü–∞—Ä—Å–∏–Ω–≥ HireHi —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {url}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Playwright –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ (—Å–∞–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π)
            if get_page_with_playwright_sync:
                logging.info("üé≠ –ò—Å–ø–æ–ª—å–∑—É–µ–º Playwright —Å –ø–æ–ª–Ω–æ–π —ç–º—É–ª—è—Ü–∏–µ–π –±—Ä–∞—É–∑–µ—Ä–∞")
                html = get_page_with_playwright_sync(url)
                
                if html:
                    soup = BeautifulSoup(html, 'html.parser')
                    logging.info("‚úÖ –£—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ Playwright")
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—Ö
                    if log_success_event:
                        log_success_event('hirehi', 3.0)  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è –¥–ª—è Playwright
                else:
                    logging.warning("‚ö†Ô∏è Playwright –Ω–µ —Å–º–æ–≥ –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É, –ø—Ä–æ–±—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–æ–¥—É–ª—å")
                    # Fallback –Ω–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–æ–¥—É–ª—å –æ–±—Ö–æ–¥–∞
                    if get_hirehi_page:
                        response = get_hirehi_page(url)
                        
                        if response and response.status_code == 200:
                            soup = BeautifulSoup(response.content, 'html.parser')
                            logging.info("‚úÖ –£—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–æ–¥—É–ª—å –æ–±—Ö–æ–¥–∞")
                            
                            # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—Ö
                            if log_success_event:
                                log_success_event('hirehi', response.elapsed.total_seconds())
                        else:
                            logging.warning("‚ö†Ô∏è –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–æ–¥—É–ª—å –æ–±—Ö–æ–¥–∞ —Ç–æ–∂–µ –Ω–µ —Å–º–æ–≥ –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É")
                            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                            try:
                                response = self.session.get(url, timeout=self.timeout)
                                if response.status_code == 200:
                                    soup = BeautifulSoup(response.content, 'html.parser')
                                    logging.info("‚úÖ –£—Å–ø–µ—à–Ω—ã–π fallback –∑–∞–ø—Ä–æ—Å")
                                    
                                    # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—Ö
                                    if log_success_event:
                                        log_success_event('hirehi', response.elapsed.total_seconds())
                                else:
                                    raise requests.RequestException(f"HTTP {response.status_code}")
                            except requests.RequestException as e:
                                logging.error(f"‚ùå –í—Å–µ –º–µ—Ç–æ–¥—ã –∑–∞–ø—Ä–æ—Å–∞ –Ω–µ —É–¥–∞–ª–∏—Å—å: {e}")
                                # –õ–æ–≥–∏—Ä—É–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
                                if log_blocking_event:
                                    log_blocking_event('hirehi', url, getattr(e.response, 'status_code', 0) if hasattr(e, 'response') else 0, 
                                                     str(e), self.session.headers.get('User-Agent', 'Unknown'))
                                return []
                    else:
                        logging.error("‚ùå –í—Å–µ –º–æ–¥—É–ª–∏ –æ–±—Ö–æ–¥–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
                        return []
            else:
                # Playwright –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–æ–¥—É–ª—å
                logging.warning("‚ö†Ô∏è Playwright –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–æ–¥—É–ª—å –æ–±—Ö–æ–¥–∞")
                if get_hirehi_page:
                    response = get_hirehi_page(url)
                    
                    if response and response.status_code == 200:
                        soup = BeautifulSoup(response.content, 'html.parser')
                        logging.info("‚úÖ –£—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–æ–¥—É–ª—å –æ–±—Ö–æ–¥–∞")
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—Ö
                        if log_success_event:
                            log_success_event('hirehi', response.elapsed.total_seconds())
                    else:
                        logging.warning("‚ö†Ô∏è –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–æ–¥—É–ª—å –æ–±—Ö–æ–¥–∞ –Ω–µ —Å–º–æ–≥ –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É")
                        # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                        try:
                            response = self.session.get(url, timeout=self.timeout)
                            response.raise_for_status()
                            soup = BeautifulSoup(response.content, 'html.parser')
                            
                            # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—Ö
                            if log_success_event:
                                log_success_event('hirehi', response.elapsed.total_seconds())
                                
                        except requests.RequestException as e:
                            logging.warning(f"–û–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å –Ω–µ —É–¥–∞–ª—Å—è: {e}")
                            # –õ–æ–≥–∏—Ä—É–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
                            if log_blocking_event:
                                log_blocking_event('hirehi', url, getattr(e.response, 'status_code', 0) if hasattr(e, 'response') else 0, 
                                                 str(e), self.session.headers.get('User-Agent', 'Unknown'))
                            return []
                else:
                    logging.error("‚ùå –í—Å–µ –º–æ–¥—É–ª–∏ –æ–±—Ö–æ–¥–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
                    return []
            
            # –ò—â–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
            vacancy_selectors = [
                'div.job-card',
                'div.vacancy-card',
                'article.job-item',
                'div[data-testid="job-card"]',
                'a[href*="/job/"]',
                'a[href*="/vacancy/"]'
            ]
            
            vacancies_found = []
            for selector in vacancy_selectors:
                vacancies_found = soup.select(selector)
                if vacancies_found:
                    logging.info(f"–ù–∞–π–¥–µ–Ω–æ {len(vacancies_found)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä: {selector}")
                    break
            
            if not vacancies_found:
                # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏–∏
                job_links = soup.find_all('a', href=lambda x: x and ('/job/' in x or '/vacancy/' in x))
                if job_links:
                    logging.info(f"–ù–∞–π–¥–µ–Ω–æ {len(job_links)} —Å—Å—ã–ª–æ–∫ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏–∏")
                    vacancies_found = job_links
                else:
                    logging.warning(f"–ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π")
                    return []
            
            parsed_vacancies = []
            processed_urls = set()  # –î–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            
            for vacancy_elem in vacancies_found:
                try:
                    # –ï—Å–ª–∏ —ç—Ç–æ —Å—Å—ã–ª–∫–∞, –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –Ω–µ—ë
                    if vacancy_elem.name == 'a':
                        title = vacancy_elem.get_text(strip=True)
                        url = vacancy_elem.get('href', '')
                        
                        if not title or not url:
                            continue
                        
                        # –ò—â–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ
                        parent = vacancy_elem.find_parent()
                        company = ''
                        salary = ''
                        location = ''
                        description = ''
                        
                        if parent:
                            # –ò—â–µ–º –∫–æ–º–ø–∞–Ω–∏—é
                            company_elem = parent.find(['span', 'div', 'p'], string=lambda x: x and len(x) < 100)
                            if company_elem and company_elem != vacancy_elem:
                                company = company_elem.get_text(strip=True)
                            
                            # –ò—â–µ–º –∑–∞—Ä–ø–ª–∞—Ç—É
                            salary_text = parent.get_text()
                            if any(currency in salary_text for currency in ['$', '‚Ç¨', '‚ÇΩ', 'USD', 'EUR', 'RUB']):
                                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞—Ä–ø–ª–∞—Ç—É —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º –≤—ã—Ä–∞–∂–µ–Ω–∏–µ–º
                                import re
                                salary_match = re.search(r'[\d\s,]+\s*[$‚Ç¨‚ÇΩ]|[$‚Ç¨‚ÇΩ]\s*[\d\s,]+|\d+\s*(USD|EUR|RUB)', salary_text)
                                if salary_match:
                                    salary = salary_match.group(0).strip()
                    
                    else:
                        # –ï—Å–ª–∏ —ç—Ç–æ –∫–∞—Ä—Ç–æ—á–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–∏, –∏—â–µ–º —Å—Å—ã–ª–∫—É –≤–Ω—É—Ç—Ä–∏
                        title_elem = vacancy_elem.find('a', href=lambda x: x and ('/job/' in x or '/vacancy/' in x))
                        if not title_elem:
                            # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ –¥—Ä—É–≥–∏–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
                            title_elem = vacancy_elem.find(['h1', 'h2', 'h3', 'h4'])
                            if title_elem:
                                # –ò—â–µ–º —Å—Å—ã–ª–∫—É —Ä—è–¥–æ–º
                                link_elem = vacancy_elem.find('a', href=True)
                                if link_elem:
                                    title = title_elem.get_text(strip=True)
                                    url = link_elem.get('href', '')
                                else:
                                    continue
                            else:
                                continue
                        else:
                            title = title_elem.get_text(strip=True)
                            url = title_elem.get('href', '')
                        
                        if not title or not url:
                            continue
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–ø–∞–Ω–∏—é
                        company_selectors = [
                            '.company-name',
                            '.job-company',
                            '.vacancy-company',
                            '[data-testid="company-name"]'
                        ]
                        
                        company = '–ö–æ–º–ø–∞–Ω–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω–∞'
                        for company_selector in company_selectors:
                            company_elem = vacancy_elem.select_one(company_selector)
                            if company_elem:
                                company = company_elem.get_text(strip=True)
                                break
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞—Ä–ø–ª–∞—Ç—É
                        salary_selectors = [
                            '.salary',
                            '.job-salary',
                            '.vacancy-salary',
                            '[data-testid="salary"]'
                        ]
                        
                        salary = '–ù–µ —É–∫–∞–∑–∞–Ω–∞'
                        for salary_selector in salary_selectors:
                            salary_elem = vacancy_elem.select_one(salary_selector)
                            if salary_elem:
                                salary = salary_elem.get_text(strip=True)
                                break
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
                        description_selectors = [
                            '.job-description',
                            '.vacancy-description',
                            '.description',
                            '.snippet'
                        ]
                        
                        description = ''
                        for desc_selector in description_selectors:
                            desc_elem = vacancy_elem.select_one(desc_selector)
                            if desc_elem:
                                description = desc_elem.get_text(strip=True)
                                break
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ª–æ–∫–∞—Ü–∏—é
                        location_selectors = [
                            '.location',
                            '.job-location',
                            '.vacancy-location',
                            '[data-testid="location"]'
                        ]
                        
                        location = ''
                        for location_selector in location_selectors:
                            location_elem = vacancy_elem.select_one(location_selector)
                            if location_elem:
                                location = location_elem.get_text(strip=True)
                                break
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                    if not self.is_relevant_vacancy(title, description):
                        logging.debug(f"–ù–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –≤–∞–∫–∞–Ω—Å–∏—è: {title}")
                        continue
                    
                    # –ü–æ–ª–Ω—ã–π URL
                    full_url = urljoin('https://hirehi.com', url)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
                    if full_url in processed_urls:
                        continue
                    processed_urls.add(full_url)
                    
                    vacancy_id = self.extract_vacancy_id(full_url)
                    
                    vacancy_data = {
                        'external_id': f"hirehi-{vacancy_id}",
                        'url': full_url,
                        'title': title,
                        'company': company,
                        'salary': salary,
                        'location': location,
                        'description': description,
                        'source': 'hirehi'
                    }
                    
                    parsed_vacancies.append(vacancy_data)
                    logging.info(f"–ù–∞–π–¥–µ–Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –≤–∞–∫–∞–Ω—Å–∏—è: {title} - {company}")
                    
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
                    continue
            
            return parsed_vacancies
            
        except requests.RequestException as e:
            logging.error(f"–û—à–∏–±–∫–∞ HTTP –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
            return []
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
            return []
    
    def extract_full_vacancy_details(self, vacancy_url: str) -> Dict[str, str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã HireHi"""
        try:
            logging.debug(f"–ò–∑–≤–ª–µ–∫–∞–µ–º –¥–µ—Ç–∞–ª–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {vacancy_url}")
            
            response = self.session.get(vacancy_url, timeout=self.timeout)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º
            description_selectors = [
                '.job-description',
                '.vacancy-description',
                '.description',
                '.job-content',
                '.vacancy-content',
                '[data-testid="job-description"]',
                '.content'
            ]
            
            description_element = None
            
            for selector in description_selectors:
                element = soup.select_one(selector)
                if element:
                    description_element = element
                    logging.debug(f"–ù–∞–π–¥–µ–Ω –±–ª–æ–∫ –æ–ø–∏—Å–∞–Ω–∏—è —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä {selector}")
                    break
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã, –±–µ—Ä—ë–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if not description_element:
                body = soup.find('body')
                if body:
                    description_element = body
                    logging.debug("–ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
            
            if not description_element:
                logging.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω –±–ª–æ–∫ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è {vacancy_url}")
                return {
                    'full_description': '–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ',
                    'requirements': '',
                    'tasks': '',
                    'benefits': '',
                    'conditions': ''
                }
            
            # –ü—Ä–æ—Å—Ç–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∫–∞–∫ –µ—Å—Ç—å
            full_description = extract_formatted_text(description_element)
            full_description = clean_text(full_description)
            
            # –ù–µ —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–ª–æ–∫–∏ - –≤—Å–µ –∏–¥–µ—Ç –≤ full_description
            requirements = ''
            tasks = ''
            conditions = ''
            benefits = ''
            
            return {
                'full_description': full_description or '–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ',
                'requirements': requirements or '',
                'tasks': tasks or '',
                'benefits': benefits or '',
                'conditions': conditions or ''
            }
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π –≤–∞–∫–∞–Ω—Å–∏–∏ {vacancy_url}: {e}")
            return {
                'full_description': '–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ',
                'requirements': '–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω—ã',
                'tasks': '–ó–∞–¥–∞—á–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã',
                'benefits': '–õ—å–≥–æ—Ç—ã –Ω–µ —É–∫–∞–∑–∞–Ω—ã',
                'conditions': '–£—Å–ª–æ–≤–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω—ã'
            }
    
    def parse_vacancies(self, query: str = '–¥–∏–∑–∞–π–Ω–µ—Ä', pages: int = 3, extract_details: bool = True) -> List[Dict[str, Any]]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–π HireHi"""
        logging.info(f"–ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ HireHi")
        logging.info(f"–ó–∞–ø—Ä–æ—Å: '{query}', —Å—Ç—Ä–∞–Ω–∏—Ü: {pages}, –¥–µ—Ç–∞–ª–∏: {extract_details}")
        
        all_vacancies = []
        
        for page in range(1, pages + 1):
            try:
                # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–æ —Å–ø–∏—Å–∫–æ–º
                page_vacancies = self.parse_vacancy_list_page(query, page)
                
                if not page_vacancies:
                    logging.warning(f"–ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π")
                    continue
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–µ—Ç–∞–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏
                for vacancy in page_vacancies:
                    try:
                        if extract_details:
                            details = self.extract_full_vacancy_details(vacancy['url'])
                            vacancy.update(details)
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                        vacancy['published_at'] = datetime.now().isoformat()
                        vacancy['status'] = 'pending'
                        
                        all_vacancies.append(vacancy)
                        
                        # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–µ—Ç–∞–ª–µ–π
                        if extract_details:
                            time.sleep(self.delay)
                        
                    except Exception as e:
                        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
                        continue
                
                logging.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –Ω–∞–π–¥–µ–Ω–æ {len(page_vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π")
                
                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
                time.sleep(self.delay)
                
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
                continue
        
        logging.info(f"HireHi –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω. –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(all_vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π")
        return all_vacancies


def main():
    """–¢–µ—Å—Ç–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('hirehi_parser.log', encoding='utf-8')
        ]
    )
    
    parser = argparse.ArgumentParser(description='HireHi –ø–∞—Ä—Å–µ—Ä –¥–ª—è –¥–∏–∑–∞–π–Ω–µ—Ä—Å–∫–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π')
    parser.add_argument('--query', default='–¥–∏–∑–∞–π–Ω–µ—Ä', help='–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å')
    parser.add_argument('--pages', type=int, default=3, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü')
    parser.add_argument('--delay', type=float, default=1.0, help='–ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏')
    parser.add_argument('--no-details', action='store_true', help='–ù–µ –∏–∑–≤–ª–µ–∫–∞—Ç—å –ø–æ–ª–Ω—ã–µ –¥–µ—Ç–∞–ª–∏')
    
    args = parser.parse_args()
    
    try:
        hirehi_parser = HireHiParser(delay=args.delay)
        vacancies = hirehi_parser.parse_vacancies(
            query=args.query,
            pages=args.pages,
            extract_details=not args.no_details
        )
        
        print(f"\n–ù–∞–π–¥–µ–Ω–æ {len(vacancies)} –¥–∏–∑–∞–π–Ω–µ—Ä—Å–∫–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ HireHi:")
        for i, vacancy in enumerate(vacancies, 1):
            print(f"{i}. {vacancy['title']}")
            print(f"   –ö–æ–º–ø–∞–Ω–∏—è: {vacancy['company']}")
            print(f"   –ó–∞—Ä–ø–ª–∞—Ç–∞: {vacancy['salary']}")
            print(f"   URL: {vacancy['url']}")
            print()
        
    except Exception as e:
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
